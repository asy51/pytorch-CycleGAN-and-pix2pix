{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai.transforms as MT\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import einops\n",
    "import monai\n",
    "import os\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data.fast_dataset import FastTXDS\n",
    "from bmel.data.fastmri import FastMRIDataset, FastMRITranslateDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from data.ct_dataset import CTSliceDataset, CTDataset\n",
    "from data import getds\n",
    "import myutil\n",
    "from models import create_model\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'ct_86_vols'\n",
    "epoch_ndx = 650\n",
    "opt = myutil.load_opts(name)\n",
    "opt.phase = 'test'\n",
    "opt.epoch = epoch_ndx\n",
    "opt.num_threads = 0   # test code only supports num_threads = 0\n",
    "opt.batch_size = 1    # test code only supports batch_size = 1\n",
    "opt.serial_batches = True  # disable data shuffling; comment this line if results on randomly chosen images are needed.\n",
    "opt.no_flip = True    # no flip; comment this line if results on flipped images are needed.\n",
    "opt.display_id = -1   # no visdom display; the test code saves the results to a HTML file.\n",
    "opt.isTrain = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80, 1, 75, 25, 15, 60, 13, 21, 5, 71, 65, 68, 57, 78, 66, 70, 36, 83]\n",
      "loading volume_id=80[1]\n",
      "loading volume_id=80[4]\n"
     ]
    }
   ],
   "source": [
    "_, ds = CTSliceDataset.split()\n",
    "print(ds.volume_ids)\n",
    "ds.volume_ids = [80]\n",
    "ds.preload()\n",
    "dl = torch.utils.data.DataLoader(ds, batch_size=opt.batch_size, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "loading the model from ./checkpoints/ct_86_vols/650_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 29.238 M\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = create_model(opt)\n",
    "model.setup(opt)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|‚ñç         | 135/2726 [00:00<00:07, 351.55it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = {volume_id: {} for volume_id in ds.volume_ids}\n",
    "\n",
    "for sample_ndx, sample in enumerate(tqdm(ds)):\n",
    "    volume_id = sample['volume_id']\n",
    "    slc_ndx = sample['slc_ndx']\n",
    "    sample['A'] = sample['A'].unsqueeze(0)\n",
    "    sample['B'] = sample['B'].unsqueeze(0)\n",
    "    if volume_id != 80: continue\n",
    "    model.set_input(sample)\n",
    "    model.test()\n",
    "    visuals = model.get_current_visuals()\n",
    "    for k in visuals:\n",
    "        visuals[k] = visuals[k][0,0].cpu()\n",
    "    preds[volume_id][slc_ndx] = visuals['fake_B']\n",
    "    # fig, ax = plt.subplots(1, 4, figsize=(40, 10))\n",
    "    # im = ax[0].imshow(visuals['real_A'], 'gray'); plt.colorbar(im, ax=ax[0])\n",
    "    # im = ax[1].imshow(visuals['fake_B'], 'gray'); plt.colorbar(im, ax=ax[1])\n",
    "    # im = ax[2].imshow(visuals['real_B'], 'gray'); plt.colorbar(im, ax=ax[2])\n",
    "    # im = ax[3].imshow(visuals['real_B'] - visuals['fake_B'], 'gray'); plt.colorbar(im, ax=ax[3])\n",
    "    # plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = preds[80]\n",
    "assert all(slc_ndx in pred for slc_ndx in range(len(pred)))\n",
    "pred = torch.stack([pred[slc_ndx] for slc_ndx in sorted(pred)])\n",
    "# ds.volumes[80][4], ds.volumes[80][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8984), tensor(1.), tensor(1.))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.max(), ds.volumes[80][4][0].max(), ds.volumes[80][1][0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.4204e-05)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.mse_loss(ds.volumes[80][1][0], ds.volumes[80][4][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
